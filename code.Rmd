---
title: "Paris House Pricing Prediction Model Using Bayesian Method"
author: "Elvina Benedicta Santoso"
date: "2023-12-29"
output:
  pdf_document: default
  html_document: default
---

# Load library
```{r}
library(coda)
library(rjags)
library(knitr)
library(purrr)
library(tidyr)
library(ggplot2)
```

# Set Seed
```{r}
set.seed(123)
```

# Load Data
```{r}
df <- read.csv('./ParisHousing.csv')
head(df)
```

# Model 1
## Set Dataframe as matrix and split dependent and independent variable 
```{r}
price <- as.matrix(df$price)
Y <- price

X <- df[, c("squareMeters", "numberOfRooms", "hasYard", "hasPool", "floors", "cityCode", "numPrevOwners", "made", "isNewBuilt", "hasStormProtector", "basement", "attic", "garage", "hasStorageRoom", "hasGuestRoom", "cityPartRange")]

names <- c("price","Square Meters", "Number of Rooms", "Has Yard", "Has Pool", "Number of Floors", "City Code", "Number of Previous Owners", "Year Made", "is Newly Built", "Has Storm Protector", "Basement Area", "Attic Area", "Garage Area", "Has Storage Room", "Has Guest Room", "City Part Range")
```

## Delete Missing Value
```{r}
junk <- is.na(rowSums(X))
Y <- Y[!junk]
X <- X[!junk,]
```

## Standardize Covariates
```{r}
X <- as.matrix(scale(X))
```

## JAGS
### Put Data in JAGS Format
```{r}
n <- length(Y)
p <- ncol(X)

data <- list(Y=Y,X=X,n=n,p=p)
params <- c("alpha","beta")
burn <- 500
n.iter <- 2000
n.chains <- 3
thin <- 5
```

### Make Jags Model
```{r}
model_string <- textConnection("model{
  # Likelihood
  for(i in 1:n){
    Y[i] ~ dnorm(alpha+mu[i],taue)
    mu[i] <- inprod(X[i,],beta[])
  }
  
  # Priors
  for(j in 1:p){
    beta[j] ~ dnorm(0,0.001)
  }
  
  alpha ~ dnorm(0,0.001)
  taue ~ dgamma(0.1, 0.1)
  
  # WAIC calculations
  for(i in 1:n){
    like[i] <- dnorm(Y[i],mu[i],taue)
  }

}")
```

### Set Initial Value
```{r}
inits = list()

inits$alpha = rnorm(1)
for(i in 1:p) {
    inits$beta[i] = rnorm(1)
}
inits$taue = 10
```

## Compile Model
```{r}
model1 <- jags.model(model_string, data = data, n.chains=n.chains, quiet=TRUE, inits = inits)
```

## Update Model
```{r}
update(model1, burn)
```

## Get Posterior Samples from the model
```{r}
samples1 <- coda.samples(model1, variable.names=params, n.iter=n.iter, thin=thin)
```

## Plot MCMC Chain Trace and Features Posterior Density
```{r}
par(mar=c(1,1,1,1))
plot(samples1)
```

## Descriptive Statistics of model1
```{r}
summary(samples1)
```


## Show Alpha and Betas to the corresponding Features
```{r}
sum <- summary(samples1)
rownames(sum$statistics) <- names
rownames(sum$quantiles) <- names
sum$statistics <- round(sum$statistics,3)
sum$quantiles <- round(sum$quantiles,3)
sum
```

## Check Convergence
```{r}
gelman.diag(samples1)
```

### Compile results
```{r}
ESS1 <- effectiveSize(samples1)
out1 <- summary(samples1)$quantiles
rownames(out1)<-names

ESS1
```

## Compute DIC & WAIC
```{r}
# DIC
dic1 <- dic.samples(model1,n.iter=n.iter)

# WAIC
waic1 <- coda.samples(model1, variable.names=c("like"), n.iter=n.iter)
like1 <- waic1[[1]]
fbar1 <- colMeans(like1)
P1 <- sum(apply(log(like1),2,var))
WAIC1 <- -2*sum(log(fbar1))+2*P1
```

## Plot Posterior Density Individually
```{r}
beta <- NULL
for(l in 1:n.chains){
  beta <- rbind(beta,samples1[[l]])
}
colnames(beta) <- names
for(j in 1:17){
  hist(beta[,j],xlab=expression(beta[j]),ylab="Posterior density",
  breaks=100,main=names[j])
}
```

## SSVS
```{r}
library(knitr)
Inc_Prob <- apply(beta!=0,2,mean)
Q <- t(apply(beta,2,quantile,c(0.5,0.05,0.95)))
out <- cbind(Inc_Prob,Q)
kable(round(out,2))
```


# Model 2 (Using features that have strong correlation with the target variable based on the frequentist linear regression model)

## Build frequentist linear regression model
```{r}
price.lm <- lm(price ~ X, data = df)

summary(price.lm)
```
There are 7 variables that have a strong correlation with the variable price (indicated by 3 stars). These seven variables include squareMeters, hasYard, hasPool, floors, cityPartRange, isNewBuilt, and hasStormProtector.

## Split dependent and independent variable 
Using 7 variables that have a strong correlation with the variable price
```{r}
X <- df[, c("squareMeters", "hasYard", "hasPool", "floors", "cityPartRange", "isNewBuilt", "hasStormProtector")]
Y <- df$price
names <- c("price", "Square Meters", "Has Yard", "Has Pool", "Floors", "City Part Range", "Is New Built", "Has Storm Protector")
```

## Delete Missing Value
```{r}
junk <- is.na(rowSums(X))
Y <- Y[!junk]
X <- X[!junk,]
```

## Standardize Covariates
```{r}
X <- as.matrix(scale(X))
```

## JAGS
### Put Data in JAGS Format
```{r}
n <- length(Y)
p <- ncol(X)

data <- list(Y=Y,X=X,n=n,p=p)
params <- c("alpha","beta")
burn <- 500
n.iter <- 2000
n.chains <- 3
thin <- 5
```

### Make Jags Model
```{r}
model_string <- textConnection("model{
  # Likelihood
  for(i in 1:n){
    Y[i] ~ dnorm(alpha+mu[i],taue)
    mu[i] <- inprod(X[i,],beta[])
  }
  
  # Priors
  for(j in 1:p){
    beta[j] ~ dnorm(0,0.001)
  }
  
  alpha ~ dnorm(0,0.001)
  taue ~ dgamma(0.1, 0.1)
  
  # WAIC calculations
  for(i in 1:n){
    like[i] <- dnorm(Y[i],mu[i],taue)
  }

}")
```

### Set Initial Value
```{r}
inits = list()

inits$alpha = rnorm(1)
for(i in 1:p) {
    inits$beta[i] = rnorm(1)
}
inits$taue = 10
```

## Compile Model
```{r}
model2 <- jags.model(model_string, data = data, n.chains=n.chains, quiet=TRUE, inits = inits)
```

## Update Model
```{r}
update(model2, burn)
```

## Get Posterior Samples from the model
```{r}
samples2 <- coda.samples(model2, variable.names=params, n.iter=n.iter, thin = thin)
```

## Plot MCMC Chain Trace and Features Posterior Density
```{r}
par(mar=c(1,1,1,1))
plot(samples2)
```

## Descriptive Statistics of model2
```{r}
summary(samples2)
```

# Show Alpha and Betas to the corresponding Features
```{r}
sum <- summary(samples2)
rownames(sum$statistics) <- names
rownames(sum$quantiles) <- names
sum$statistics <- round(sum$statistics,3)
sum$quantiles <- round(sum$quantiles,3)
sum
```

## Check Convergence
```{r}
gelman.diag(samples2)
```

### Compile results
```{r}
ESS2 <- effectiveSize(samples2)
out2 <- summary(samples2)$quantiles
rownames(out2)<-names

ESS2
```

## Compute DIC & WAIC
```{r}
# DIC
dic2 <- dic.samples(model2,n.iter=n.iter)

# WAIC
waic2 <- coda.samples(model2, variable.names=c("like"), n.iter=n.iter)
like2 <- waic2[[1]]
fbar2 <- colMeans(like2)
P2 <- sum(apply(log(like2),2,var))
WAIC2 <- -2*sum(log(fbar2))+2*P2
```

## Plot Posterior Density Individually
```{r}
beta <- NULL
for(l in 1:n.chains){
  beta <- rbind(beta,samples2[[l]])
}
colnames(beta) <- names
for(j in 1:8){
  hist(beta[,j],xlab=expression(beta[j]),ylab="Posterior density",
  breaks=100,main=names[j])
}
```

# Model 3 (Same like model 2, but using initial values (alpha and beta coefficients) from the estimation of frequentist linear model)
## Split dependent and independent variable 
```{r}
X <- df[, c("squareMeters", "hasYard", "hasPool", "floors", "cityPartRange", "isNewBuilt", "hasStormProtector")]
Y <- df$price
names <- c("price", "Square Meters", "Has Yard", "Has Pool", "Floors", "City Part Range", "Is New Built", "Has Storm Protector")
```

## Delete Missing Value
```{r}
junk <- is.na(rowSums(X))
Y <- Y[!junk]
X <- X[!junk,]
```

## Standardize Covariates
```{r}
X <- as.matrix(scale(X))
```

## JAGS
### Put Data in JAGS Format
```{r}
n <- length(Y)
p <- ncol(X)

data <- list(Y=Y,X=X,n=n,p=p)
params <- c("alpha","beta")
burn <- 500
n.iter <- 2000
n.chains <- 3
thin <- 5
```

### Make Jags Model
```{r}
model_string <- textConnection("model{
  # Likelihood
  for(i in 1:n){
    Y[i] ~ dnorm(alpha+mu[i],taue)
    mu[i] <- inprod(X[i,],beta[])
  }
  
  # Priors
  for(j in 1:p){
    beta[j] ~ dnorm(0,0.001)
  }
  
  alpha ~ dnorm(0,0.001)
  taue ~ dgamma(0.1, 0.1)
  
  # WAIC calculations
  for(i in 1:n){
    like[i] <- dnorm(Y[i],mu[i],taue)
  }

}")
```

## Frequentist Linear Regression
```{r}
price.lm2 <- lm(price ~ X, data = df)

summary(price.lm2)
```
Linear regression model : 
Yi = 4993000 + 2877000 * squareMeters + 1506 * hasYard + 1489 * hasPool + 1576 * floors + 135.5 * cityPartRange + 78.68 * isNewBuilt + 71.05 * hasStormProtector

## Set Initial Value 
We use the estimation alpha and betas from Frequentist Linear Regression Model
```{r}
inits = list()

inits$alpha = 4993000
inits$beta[1] = 2877000
inits$beta[2] = 1506
inits$beta[3] = 1489
inits$beta[4] = 1576
inits$beta[5] = 135.5
inits$beta[6] = 78.68
inits$beta[7] = 71.05
inits$taue = 10
```

## Compile Model
```{r}
model3 <- jags.model(model_string, data = data, n.chains=n.chains, quiet=TRUE, inits = inits)
```

## Update Model
```{r}
update(model3, burn)
```

## Get Posterior Samples from the model
```{r}
samples3 <- coda.samples(model3, variable.names=params, n.iter=n.iter, thin=thin)
```

## Plot MCMC Chain Trace and Features Posterior Density
```{r}
par(mar=c(1,1,1,1))
plot(samples3)
```

## Descriptive Statistics of model 3
```{r}
summary(samples3)
```

# Show Alpha and Betas to the corresponding Features
```{r}
sum <- summary(samples3)
rownames(sum$statistics) <- names
rownames(sum$quantiles) <- names
sum$statistics <- round(sum$statistics,3)
sum$quantiles <- round(sum$quantiles,3)
sum
```

## Check Convergence
```{r}
gelman.diag(samples3)
```

### Compile results
```{r}
ESS3 <- effectiveSize(samples3)
out3 <- summary(samples3)$quantiles
rownames(out3)<-names

ESS3
```

## Compute DIC & WAIC
```{r}
# DIC
dic3 <- dic.samples(model3,n.iter=n.iter)

# WAIC
waic3 <- coda.samples(model3, variable.names=c("like"), n.iter=n.iter)
like3 <- waic3[[1]]
fbar3 <- colMeans(like3)
P3 <- sum(apply(log(like3),2,var))
WAIC3 <- -2*sum(log(fbar3))+2*P3
```

## Plot Posterior Density Individually
```{r}
beta <- NULL
for(l in 1:n.chains){
  beta <- rbind(beta,samples3[[l]])
}
colnames(beta) <- names
for(j in 1:8){
  hist(beta[,j],xlab=expression(beta[j]),ylab="Posterior density",
  breaks=100,main=names[j])
}
```

# Model 4
## Set Dataframe as matrix and split dependent and independent variable 
```{r}
price <- as.matrix(df$price)
Y <- price
X <- cbind(df$squareMeters, df$numberOfRooms, df$hasYard, df$hasPool, df$floors, df$cityCode, df$numPrevOwners, df$made, df$isNewBuilt, df$hasStormProtector, df$basement, df$attic, df$garage, df$hasStorageRoom, df$hasGuestRoom, df$cityPartRange)
names <- c("price","Square Meters", "Number of Rooms", "Has Yard", "Has Pool", "Number of Floors", "City Code", "Number of Previous Owners", "Year Made", "is Newly Built", "Has Storm Protector", "Basement Area", "Attic Area", "Garage Area", "Has Storage Room", "Has Guest Room", "City Part Range")
```

## Delete Missing Value
```{r}
junk <- is.na(rowSums(X))
Y <- Y[!junk]
X <- X[!junk,]
```

## Standardize Covariates
```{r}
X <- as.matrix(scale(X))
```

## JAGS
### Put Data in JAGS Format
```{r}
n <- length(Y)
p <- ncol(X)

data <- list(Y=Y,X=X,n=n,p=p)
params <- c("alpha","beta")
burn <- 500
n.iter <- 5000
n.chains <- 3
thin <- 5
```

### Make Jags Model
```{r}
model_string <- textConnection("model{
  # Likelihood
  for(i in 1:n){
    Y[i] ~ dnorm(alpha+mu[i],taue)
    mu[i] <- theta[i] + inprod(X[i,],beta[])
  }
  
  # Random Effects 
  for(j in 1:n){
    theta[j] ~ ddexp(0,taue)
  }
  
  # Priors
  for(j in 1:p){
    beta[j] ~ dnorm(0,0.001)
  }
  
  alpha ~ dnorm(0,0.001)
  taue ~ dgamma(0.1, 0.1)
  
  # WAIC calculations
  for(i in 1:n){
    like[i] <- dnorm(Y[i],mu[i],taue)
  }

}")
```

### Set Initial Value
```{r}
inits = list()

inits$alpha = rnorm(1)
for(i in 1:p) {
    inits$beta[i] = rnorm(1)
}
for(i in 1:n) {
    inits$theta[i] = rnorm(1)
}
inits$taue = 10
```

## Compile Model
```{r}
model4 <- jags.model(model_string, data = data, n.chains=n.chains, quiet=TRUE, inits = inits)
```

## Update Model
```{r}
update(model4, burn)
```

## Get Posterior Samples from the model
```{r}
samples4 <- coda.samples(model4, variable.names=params, n.iter=n.iter, thin=thin)
```

## Plot MCMC Chain Trace and Features Posterior Density
```{r}
par(mar=c(1,1,1,1))
plot(samples4)
```


# Show Alpha and Betas to the corresponding Features
```{r}
sum <- summary(samples4)
rownames(sum$statistics) <- names
rownames(sum$quantiles) <- names
sum$statistics <- round(sum$statistics,3)
sum$quantiles <- round(sum$quantiles,3)
sum
```

## Check Convergence
```{r}
gelman.diag(samples4)
```

### Compile results
```{r}
ESS2 <- effectiveSize(samples4)
out2 <- summary(samples4)$quantiles
rownames(out2)<-names

ESS2
```

## Compute DIC & WAIC
```{r}
# DIC
dic4 <- dic.samples(model4,n.iter=n.iter)

# WAIC
waic4 <- coda.samples(model4, variable.names=c("like"), n.iter=n.iter)
like4 <- waic4[[1]]
fbar4 <- colMeans(like4)
P4 <- sum(apply(log(like4),2,var))
WAIC4 <- -2*sum(log(fbar4))+2*P4
```


## DIC and WAIC comparison

```{r}
print("DIC Model 1:")
print(dic1)
```

```{r}
print("DIC Model 2:")
print(dic2)
```

```{r}
print("DIC Model 3:")
print(dic3)
```

```{r}
print("DIC Model 4:")
print(dic4)
```


```{r}
print("WAIC Model 1:")
print(WAIC1)
```

```{r}
print("WAIC Model 2:")
print(WAIC2)
```

```{r}
print("WAIC Model 3:")
print(WAIC3)
```

```{r}
print("WAIC Model 4:")
print(WAIC4)
```


